{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10b6c796",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39ead7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8764caf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:9: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/var/folders/2w/l87wj0c90l94mncxh8y9wwth0000gn/T/ipykernel_19692/810200688.py:9: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  sep='\\s+',\n"
     ]
    }
   ],
   "source": [
    "file_path = ''\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    header = f.readline().replace('\"', '').strip().split()\n",
    "\n",
    "header = ['Gene'] + header\n",
    "\n",
    "df = pd.read_csv(file_path,\n",
    "                 sep='\\s+',        \n",
    "                 quotechar='\"',    \n",
    "                 skiprows=1,       \n",
    "                 header=None)      \n",
    "\n",
    "df.columns = header\n",
    "df.set_index('Gene', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "944a9c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAAAACCTATCG_Normoxia</th>\n",
       "      <th>AAAACAACCCTA_Normoxia</th>\n",
       "      <th>AAAACACTCTCA_Normoxia</th>\n",
       "      <th>AAAACCAGGCAC_Normoxia</th>\n",
       "      <th>AAAACCTAGCTC_Normoxia</th>\n",
       "      <th>AAAACCTCCGGG_Normoxia</th>\n",
       "      <th>AAAACTCGTTGC_Normoxia</th>\n",
       "      <th>AAAAGAGCTCTC_Normoxia</th>\n",
       "      <th>AAAAGCTAGGCG_Normoxia</th>\n",
       "      <th>AAAATCGCATTT_Normoxia</th>\n",
       "      <th>...</th>\n",
       "      <th>TTTTACAGGATC_Hypoxia</th>\n",
       "      <th>TTTTACCACGTA_Hypoxia</th>\n",
       "      <th>TTTTATGCTACG_Hypoxia</th>\n",
       "      <th>TTTTCCAGACGC_Hypoxia</th>\n",
       "      <th>TTTTCGCGCTCG_Hypoxia</th>\n",
       "      <th>TTTTCGCGTAGA_Hypoxia</th>\n",
       "      <th>TTTTCGTCCGCT_Hypoxia</th>\n",
       "      <th>TTTTCTCCGGCT_Hypoxia</th>\n",
       "      <th>TTTTGTTCAAAG_Hypoxia</th>\n",
       "      <th>TTTTTTGTATGT_Hypoxia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MALAT1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT-RNR2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEAT1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H1-5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TFF1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21626 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AAAAACCTATCG_Normoxia  AAAACAACCCTA_Normoxia  AAAACACTCTCA_Normoxia  \\\n",
       "Gene                                                                           \n",
       "MALAT1                       1                      3                      3   \n",
       "MT-RNR2                      0                      0                      0   \n",
       "NEAT1                        0                      0                      0   \n",
       "H1-5                         0                      0                      0   \n",
       "TFF1                         4                      1                      1   \n",
       "\n",
       "         AAAACCAGGCAC_Normoxia  AAAACCTAGCTC_Normoxia  AAAACCTCCGGG_Normoxia  \\\n",
       "Gene                                                                           \n",
       "MALAT1                       6                      4                      5   \n",
       "MT-RNR2                      2                      0                      0   \n",
       "NEAT1                        0                      0                      2   \n",
       "H1-5                         0                      0                      2   \n",
       "TFF1                         1                      0                      0   \n",
       "\n",
       "         AAAACTCGTTGC_Normoxia  AAAAGAGCTCTC_Normoxia  AAAAGCTAGGCG_Normoxia  \\\n",
       "Gene                                                                           \n",
       "MALAT1                       1                     13                      3   \n",
       "MT-RNR2                      2                      1                      7   \n",
       "NEAT1                        0                      1                      2   \n",
       "H1-5                         0                      0                      0   \n",
       "TFF1                         0                      2                      0   \n",
       "\n",
       "         AAAATCGCATTT_Normoxia  ...  TTTTACAGGATC_Hypoxia  \\\n",
       "Gene                            ...                         \n",
       "MALAT1                       3  ...                     0   \n",
       "MT-RNR2                      0  ...                     0   \n",
       "NEAT1                        0  ...                     0   \n",
       "H1-5                         0  ...                     0   \n",
       "TFF1                         1  ...                     2   \n",
       "\n",
       "         TTTTACCACGTA_Hypoxia  TTTTATGCTACG_Hypoxia  TTTTCCAGACGC_Hypoxia  \\\n",
       "Gene                                                                        \n",
       "MALAT1                      2                     1                     0   \n",
       "MT-RNR2                     0                     0                     0   \n",
       "NEAT1                       0                     0                     0   \n",
       "H1-5                        1                     0                     0   \n",
       "TFF1                        3                     8                     0   \n",
       "\n",
       "         TTTTCGCGCTCG_Hypoxia  TTTTCGCGTAGA_Hypoxia  TTTTCGTCCGCT_Hypoxia  \\\n",
       "Gene                                                                        \n",
       "MALAT1                      1                     0                     1   \n",
       "MT-RNR2                     0                     0                     0   \n",
       "NEAT1                       0                     0                     0   \n",
       "H1-5                        1                     0                     0   \n",
       "TFF1                        0                     3                     4   \n",
       "\n",
       "         TTTTCTCCGGCT_Hypoxia  TTTTGTTCAAAG_Hypoxia  TTTTTTGTATGT_Hypoxia  \n",
       "Gene                                                                       \n",
       "MALAT1                      0                     0                     4  \n",
       "MT-RNR2                     0                     0                     0  \n",
       "NEAT1                       0                     0                     0  \n",
       "H1-5                        1                     0                     0  \n",
       "TFF1                        2                     6                     0  \n",
       "\n",
       "[5 rows x 21626 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bf0be33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 21626)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714c3475",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "print(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "13178815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAAAACCTATCG_Normoxia</th>\n",
       "      <th>AAAACAACCCTA_Normoxia</th>\n",
       "      <th>AAAACACTCTCA_Normoxia</th>\n",
       "      <th>AAAACCAGGCAC_Normoxia</th>\n",
       "      <th>AAAACCTAGCTC_Normoxia</th>\n",
       "      <th>AAAACCTCCGGG_Normoxia</th>\n",
       "      <th>AAAACTCGTTGC_Normoxia</th>\n",
       "      <th>AAAAGAGCTCTC_Normoxia</th>\n",
       "      <th>AAAAGCTAGGCG_Normoxia</th>\n",
       "      <th>AAAATCGCATTT_Normoxia</th>\n",
       "      <th>...</th>\n",
       "      <th>TTTTACAGGATC_Hypoxia</th>\n",
       "      <th>TTTTACCACGTA_Hypoxia</th>\n",
       "      <th>TTTTATGCTACG_Hypoxia</th>\n",
       "      <th>TTTTCCAGACGC_Hypoxia</th>\n",
       "      <th>TTTTCGCGCTCG_Hypoxia</th>\n",
       "      <th>TTTTCGCGTAGA_Hypoxia</th>\n",
       "      <th>TTTTCGTCCGCT_Hypoxia</th>\n",
       "      <th>TTTTCTCCGGCT_Hypoxia</th>\n",
       "      <th>TTTTGTTCAAAG_Hypoxia</th>\n",
       "      <th>TTTTTTGTATGT_Hypoxia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.030333</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.032333</td>\n",
       "      <td>0.045333</td>\n",
       "      <td>0.047333</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.027333</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.027333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052333</td>\n",
       "      <td>0.043667</td>\n",
       "      <td>0.033667</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.025333</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.046333</td>\n",
       "      <td>0.055667</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.033000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.277254</td>\n",
       "      <td>0.220823</td>\n",
       "      <td>0.195662</td>\n",
       "      <td>0.233751</td>\n",
       "      <td>0.246235</td>\n",
       "      <td>0.299649</td>\n",
       "      <td>0.204403</td>\n",
       "      <td>0.292030</td>\n",
       "      <td>0.281074</td>\n",
       "      <td>0.237918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364654</td>\n",
       "      <td>0.244499</td>\n",
       "      <td>0.340449</td>\n",
       "      <td>0.302117</td>\n",
       "      <td>0.208261</td>\n",
       "      <td>0.286924</td>\n",
       "      <td>0.301469</td>\n",
       "      <td>0.358623</td>\n",
       "      <td>0.240642</td>\n",
       "      <td>0.244808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21626 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AAAAACCTATCG_Normoxia  AAAACAACCCTA_Normoxia  AAAACACTCTCA_Normoxia  \\\n",
       "count            3000.000000            3000.000000            3000.000000   \n",
       "mean                0.034000               0.030333               0.027000   \n",
       "std                 0.277254               0.220823               0.195662   \n",
       "min                 0.000000               0.000000               0.000000   \n",
       "25%                 0.000000               0.000000               0.000000   \n",
       "50%                 0.000000               0.000000               0.000000   \n",
       "75%                 0.000000               0.000000               0.000000   \n",
       "max                 4.000000               4.000000               5.000000   \n",
       "\n",
       "       AAAACCAGGCAC_Normoxia  AAAACCTAGCTC_Normoxia  AAAACCTCCGGG_Normoxia  \\\n",
       "count            3000.000000            3000.000000            3000.000000   \n",
       "mean                0.032333               0.045333               0.047333   \n",
       "std                 0.233751               0.246235               0.299649   \n",
       "min                 0.000000               0.000000               0.000000   \n",
       "25%                 0.000000               0.000000               0.000000   \n",
       "50%                 0.000000               0.000000               0.000000   \n",
       "75%                 0.000000               0.000000               0.000000   \n",
       "max                 6.000000               4.000000               8.000000   \n",
       "\n",
       "       AAAACTCGTTGC_Normoxia  AAAAGAGCTCTC_Normoxia  AAAAGCTAGGCG_Normoxia  \\\n",
       "count            3000.000000            3000.000000            3000.000000   \n",
       "mean                0.030000               0.027333               0.032000   \n",
       "std                 0.204403               0.292030               0.281074   \n",
       "min                 0.000000               0.000000               0.000000   \n",
       "25%                 0.000000               0.000000               0.000000   \n",
       "50%                 0.000000               0.000000               0.000000   \n",
       "75%                 0.000000               0.000000               0.000000   \n",
       "max                 6.000000              13.000000               7.000000   \n",
       "\n",
       "       AAAATCGCATTT_Normoxia  ...  TTTTACAGGATC_Hypoxia  TTTTACCACGTA_Hypoxia  \\\n",
       "count            3000.000000  ...           3000.000000           3000.000000   \n",
       "mean                0.027333  ...              0.052333              0.043667   \n",
       "std                 0.237918  ...              0.364654              0.244499   \n",
       "min                 0.000000  ...              0.000000              0.000000   \n",
       "25%                 0.000000  ...              0.000000              0.000000   \n",
       "50%                 0.000000  ...              0.000000              0.000000   \n",
       "75%                 0.000000  ...              0.000000              0.000000   \n",
       "max                 6.000000  ...              7.000000              4.000000   \n",
       "\n",
       "       TTTTATGCTACG_Hypoxia  TTTTCCAGACGC_Hypoxia  TTTTCGCGCTCG_Hypoxia  \\\n",
       "count           3000.000000           3000.000000           3000.000000   \n",
       "mean               0.033667              0.033000              0.025333   \n",
       "std                0.340449              0.302117              0.208261   \n",
       "min                0.000000              0.000000              0.000000   \n",
       "25%                0.000000              0.000000              0.000000   \n",
       "50%                0.000000              0.000000              0.000000   \n",
       "75%                0.000000              0.000000              0.000000   \n",
       "max               10.000000              8.000000              6.000000   \n",
       "\n",
       "       TTTTCGCGTAGA_Hypoxia  TTTTCGTCCGCT_Hypoxia  TTTTCTCCGGCT_Hypoxia  \\\n",
       "count           3000.000000           3000.000000           3000.000000   \n",
       "mean               0.037000              0.046333              0.055667   \n",
       "std                0.286924              0.301469              0.358623   \n",
       "min                0.000000              0.000000              0.000000   \n",
       "25%                0.000000              0.000000              0.000000   \n",
       "50%                0.000000              0.000000              0.000000   \n",
       "75%                0.000000              0.000000              0.000000   \n",
       "max                7.000000              7.000000              9.000000   \n",
       "\n",
       "       TTTTGTTCAAAG_Hypoxia  TTTTTTGTATGT_Hypoxia  \n",
       "count           3000.000000           3000.000000  \n",
       "mean               0.038000              0.033000  \n",
       "std                0.240642              0.244808  \n",
       "min                0.000000              0.000000  \n",
       "25%                0.000000              0.000000  \n",
       "50%                0.000000              0.000000  \n",
       "75%                0.000000              0.000000  \n",
       "max                6.000000              6.000000  \n",
       "\n",
       "[8 rows x 21626 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a61f2bf",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed76f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnames = list(df.columns)\n",
    "cnames[100]\n",
    "sns.boxplot(x=df[cnames[100]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e772db46",
   "metadata": {},
   "source": [
    "This boxplot shows the distribution of values in the AACAATGGGGG_Normoxia column. Most values are clustered at zero, while a few outliers (the diamonds) have higher values up to 4. This suggests that our variable is sparse and highly skewed, with the majority of observations showing no activity or expression, and only a few showing higher levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815fd416",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x=df[cnames[100]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8113083d",
   "metadata": {},
   "source": [
    "This violin plot shows the distribution density of values in the AACAATGGGGG_Normoxia column. The plot confirms that most values are concentrated at zero, with a few sparse, higher values. The wide section near 0 indicates a high proportion of zeros, while the long flat tail toward higher values (1–4) represents rare outliers or highly variable expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a741b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_stats = pd.DataFrame(index=df.index)  \n",
    "gene_stats['mean'] = df.mean(axis=1)\n",
    "gene_stats['std'] = df.std(axis=1)\n",
    "gene_stats['min'] = df.min(axis=1)\n",
    "gene_stats['max'] = df.max(axis=1)\n",
    "gene_stats['zero_fraction'] = (df == 0).sum(axis=1) / df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b999af5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_stats['mean'].hist(bins=50)\n",
    "plt.title(\"Histogram of Mean Gene Expression\")\n",
    "plt.xlabel(\"Mean Expression\")\n",
    "plt.ylabel(\"Number of Genes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fae551",
   "metadata": {},
   "source": [
    "This histogram shows the distribution of mean gene expression levels across all genes in our dataset. The majority of genes have a very low mean expression, with most clustered near zero. Only a small number of genes show higher mean expression values (> 0.5). This is a typical pattern in gene expression data, where most genes are inactive or lowly expressed, while a few genes are highly expressed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1234bc19",
   "metadata": {},
   "source": [
    "Since our data is big, we will look ata the most expressed genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1ecf18d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_variable_genes = gene_stats['std'].sort_values(ascending=False).head(50).index\n",
    "df_filtered = df.loc[top_variable_genes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7f6715",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.T.boxplot(showfliers=False, figsize=(14, 6))\n",
    "plt.title(\"Expression Distribution per Sample (Top 50 Genes)\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d2cfd7",
   "metadata": {},
   "source": [
    "This boxplot shows the expression distribution per sample for the top 50 most variable genes. Each box represents one gene, with its name on the x-axis, and shows the range and spread of expression counts across all samples. The plot highlights that certain genes (e.g. MALAT1, BCRYN1) show higher and more variable expression, while most other genes have lower expression levels with relatively small variability. This helps identify which genes are the most dynamic across the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0859f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "top_50 = df_filtered.var(axis=1).sort_values(ascending=False).head(50).index\n",
    "top_50_data = df_filtered.loc[top_50]\n",
    "\n",
    "zscore_data = (top_50_data - top_50_data.mean(axis=1).values[:, None]) / top_50_data.std(axis=1).values[:, None]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(zscore_data, cmap='viridis', xticklabels=False)\n",
    "plt.title(\"Heatmap: Top 50 Most Variable Genes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34da5169",
   "metadata": {},
   "source": [
    "This heatmap shows the expression levels of the top 50 most variable genes across all samples. Each row represents a gene, and each column represents a sample. The color scale indicates expression levels (purple = low, yellow = high). The heatmap allows us to visually detect patterns, clusters, or outliers in gene expression. For example, certain genes like MALAT1 and BCRYN1 show some samples with notably higher expression (yellow streaks), while others remain low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99de232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df.iloc[:, :50]\n",
    "np.shape(df_small)\n",
    "plt.figure(figsize=(16,4))\n",
    "plot=sns.violinplot(data=df_small,palette=\"Set3\",cut=0)\n",
    "plt.setp(plot.get_xticklabels(), rotation=90)\n",
    "plt.title('Violin plot of the first 50 genes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaa5df8",
   "metadata": {},
   "source": [
    "This violin plot shows the expression distribution of the first 50 genes (under normoxia conditions) across all samples. For each gene (x-axis), the plot displays how its expression values are distributed. The majority of genes show a large number of low or zero expressions, with some genes having a long tail toward higher expression values, indicating rare but strong expression in certain samples. The variability across genes suggests that some motifs or sequences are more actively expressed than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476e4852",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_stats['variance'] = df.var(axis=1)\n",
    "\n",
    "plt.scatter(gene_stats['mean'], gene_stats['variance'], alpha=0.5, s=10)\n",
    "plt.title(\"Mean vs Variance of Gene Expression\")\n",
    "plt.xlabel(\"Mean Expression\")\n",
    "plt.ylabel(\"Variance\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f55c47",
   "metadata": {},
   "source": [
    "In this scatter plot, we can see the relationship between mean gene expression and variance of gene expression across all genes. Both axes are on a log scale. The plot reveals a clear positive correlation: genes with higher mean expression tend to have higher variance. This is expected in gene expression data, as more actively expressed genes typically show more variability across samples. The plot also helps identify genes that may have unusually high variance relative to their mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3827b314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 97.53%\n"
     ]
    }
   ],
   "source": [
    "total_values = df.size\n",
    "\n",
    "zero_values = (df == 0).sum().sum()\n",
    "\n",
    "sparsity = zero_values / total_values\n",
    "print(f\"Sparsity: {sparsity:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3098720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis, skew\n",
    "colN = np.shape(df)[1]\n",
    "colN\n",
    "df_skew_cells = []\n",
    "for i in range(colN) :\n",
    "     v_df = df[cnames[i]]\n",
    "     df_skew_cells += [skew(v_df)]\n",
    "df_skew_cells\n",
    "sns.histplot(df_skew_cells,bins=100)\n",
    "plt.xlabel('Skewness of single cells expression profiles - original df')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce2c323",
   "metadata": {},
   "source": [
    "This histogram shows the distribution of skewness for single-cell expression profiles in the original dataframe. Skewness measures how asymmetric the expression distribution is for each cell. The plot indicates that most cells have a skewness between 5 and 15, meaning their expression profiles are right-skewed (many low-expression genes with a few high-expression ones). Some cells exhibit very high skewness (> 40), which could reflect strong outliers or rare highly expressed genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5406bee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kurt_cells = []\n",
    "for i in range(colN) :\n",
    "     v_df = df[cnames[i]]\n",
    "     df_kurt_cells += [kurtosis(v_df)]\n",
    "df_kurt_cells\n",
    "sns.histplot(df_kurt_cells,bins=100)\n",
    "plt.xlabel('Kurtosis of single cells expression profiles - original df')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9841f444",
   "metadata": {},
   "source": [
    "This histogram shows the distribution of kurtosis for single-cell expression profiles in the original dataframe. Kurtosis measures how “tailed” or “peaked” the expression distribution is in each cell. Most cells have kurtosis values between 0 and ~500, indicating moderate to high peakedness — meaning that a small number of genes in these cells have extremely high expression, while most genes remain low. Some cells exhibit very high kurtosis (> 2000), suggesting the presence of extreme outliers or very sharp peaks in gene expression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a080767",
   "metadata": {},
   "source": [
    "In the code below, we choose part of the samples so that run time is not too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8c64be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df.iloc[:, 10:30] \n",
    "sns.displot(data=df_small,palette=\"Set3\",kind=\"kde\", bw_adjust=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb6ecb7",
   "metadata": {},
   "source": [
    "In this density plot, we can see the distribution of expression values for a subset of genes (rows 10–30) under normoxia conditions. Each colored line represents one gene’s kernel density estimate (KDE) of its expression across samples. The plot reveals that most genes have a sharp peak near zero, meaning their expression is low in most samples. A few genes have longer tails toward higher values, indicating occasional higher expression. The plot highlights the sparsity and skewed nature of gene expression data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847e82dc",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "77c38a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_corr = df_small.corr() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1afb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cell_corr, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Cell-Cell Correlation Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7004c6",
   "metadata": {},
   "source": [
    "This heatmap shows the cell-cell correlation matrix for a subset of genes under normoxia conditions. Each cell in the matrix represents the correlation between the expression profiles of two cells (or samples). Dark red values along the diagonal have correlation = 1 and reflect perfect self-correlation, while off-diagonal values indicate how similar different cells’ expression profiles are. The mostly light red background suggests that cells are moderately correlated overall, with some variability in similarity between individual cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e2b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_corr = cell_corr.mean()\n",
    "low_corr_cells = mean_corr[mean_corr < 0.5]  \n",
    "print(\"Low correlation cells:\", low_corr_cells.index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648aa531",
   "metadata": {},
   "source": [
    "We choose our least mean correlation threshold as 0.5, and identify low-correlation cells. These cells have low similarity to the rest of the dataset and may represent outliers, noisy samples, or biologically distinct cells. This step is useful for filtering out or investigating potentially problematic or interesting cells in further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "aa410e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_genes = df.var(axis=1).sort_values(ascending=False).head(50).index\n",
    "gene_corr = df.loc[top_genes].T.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7795939",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(gene_corr, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Gene–Gene Correlation (Top 50 Most Variable Genes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97ce5f9",
   "metadata": {},
   "source": [
    "This heatmap shows the gene-gene correlation matrix for the top 50 most variable genes. Each cell represents the correlation between two genes’ expression profiles across all samples. The diagonal (correlation = 1) represents perfect self-correlation. The off-diagonal values reveal how similarly different genes are expressed. Some gene pairs show moderate to strong positive correlations (orange-red areas), suggesting possible co-regulation or shared biological functions, while other pairs are weakly correlated (blue areas), indicating independent expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72591eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(cell_corr)\n",
    "type(cell_corr)\n",
    "cell_corr.head(3)\n",
    "c_small=cell_corr.iloc[:,:3]\n",
    "sns.histplot(c_small,bins=100)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Correlation between cells expression profiles')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a5d736",
   "metadata": {},
   "source": [
    "This histogram shows the distribution of correlation values between the expression profiles of three specific cells (AAATCTACATA_Normoxia, AAATGGCTCTC_Normoxia, AAATGGGCCCG_Normoxia) and all other cells. For each cell, the bars indicate how frequently different correlation strengths occur. The fact that most correlations are below 0.5 reinforces that these cells are low-correlation cells, meaning their expression profiles are less similar to the majority of other cells. This result is consistent with the previous low-correlation cell selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7879d3bd",
   "metadata": {},
   "source": [
    "# Filter The Cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15837f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 21626)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc0fa27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    12705\n",
      "1     8921\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sample_names_train =df.T.index\n",
    "\n",
    "labels_array=np.array([1 if \"Hypoxia\" in name else 0 for name in sample_names_train])\n",
    "print(pd.Series(labels_array, index=sample_names_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b6dbbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_per_sample = (df != 0).sum(axis=0) \n",
    "threshold = 100  \n",
    "filtered_df = df.loc[:, nonzero_per_sample > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34e57035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 3688)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2661e08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2898\n",
      "1     790\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample_names_train =filtered_df.T.index\n",
    "\n",
    "y_train = np.array([1 if \"Hypoxia\" in name else 0 for name in sample_names_train])\n",
    "\n",
    "print(pd.Series(y_train, index=sample_names_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54b631d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_series = pd.Series(labels_array, index=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a27cd2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypoxia_cells = labels_series[labels_series == 1].index\n",
    "normoxia_cells = labels_series[labels_series == 0].index\n",
    "\n",
    "expr_hypoxia = df[hypoxia_cells]\n",
    "expr_normoxia = df[normoxia_cells]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed24e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_hypoxia = expr_hypoxia.loc[:, (expr_hypoxia != 0).sum(axis=0) >= 70]\n",
    "filtered_normoxia = expr_normoxia.loc[:, (expr_normoxia != 0).sum(axis=0) >= 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5dfdfe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = pd.concat([filtered_hypoxia, filtered_normoxia], axis=1)\n",
    "filtered_labels = labels_series[filtered_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf9fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    4768\n",
      "0    4663\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(filtered_labels.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f046ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 9431)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "763e6775",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filtered_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9180a4ec",
   "metadata": {},
   "source": [
    "# Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd765e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 9431)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee080af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9431, 3000)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df.T\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd916703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Gene</th>\n",
       "      <th>MALAT1</th>\n",
       "      <th>MT-RNR2</th>\n",
       "      <th>NEAT1</th>\n",
       "      <th>H1-5</th>\n",
       "      <th>TFF1</th>\n",
       "      <th>MT-RNR1</th>\n",
       "      <th>H4C3</th>\n",
       "      <th>GDF15</th>\n",
       "      <th>KRT81</th>\n",
       "      <th>MT-CO3</th>\n",
       "      <th>...</th>\n",
       "      <th>MROH1</th>\n",
       "      <th>SKIDA1</th>\n",
       "      <th>MICALL1</th>\n",
       "      <th>RARG</th>\n",
       "      <th>MYO1F</th>\n",
       "      <th>BRWD1-AS2</th>\n",
       "      <th>RPS19BP1</th>\n",
       "      <th>AUNIP</th>\n",
       "      <th>TNK2</th>\n",
       "      <th>SUDS3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAAAACACGATC_Hypoxia</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAAATGGGGGA_Hypoxia</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAACATCTTGC_Hypoxia</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAACCAGCCCA_Hypoxia</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAACCTTCAAG_Hypoxia</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Gene                  MALAT1  MT-RNR2  NEAT1  H1-5  TFF1  MT-RNR1  H4C3  \\\n",
       "AAAAACACGATC_Hypoxia       0        0      0     0     1        0     3   \n",
       "AAAAATGGGGGA_Hypoxia       0        0      0     0     1        0     2   \n",
       "AAAACATCTTGC_Hypoxia       2        0      0     0     1        0     1   \n",
       "AAAACCAGCCCA_Hypoxia       0        0      0     1     4        0     5   \n",
       "AAAACCTTCAAG_Hypoxia       7        0      0     0     3        0     0   \n",
       "\n",
       "Gene                  GDF15  KRT81  MT-CO3  ...  MROH1  SKIDA1  MICALL1  RARG  \\\n",
       "AAAAACACGATC_Hypoxia      0      0       0  ...      0       0        0     0   \n",
       "AAAAATGGGGGA_Hypoxia      0      0       0  ...      0       0        0     0   \n",
       "AAAACATCTTGC_Hypoxia      0      0       0  ...      0       0        0     0   \n",
       "AAAACCAGCCCA_Hypoxia      0      0       0  ...      0       0        0     0   \n",
       "AAAACCTTCAAG_Hypoxia      0      0       0  ...      0       0        0     0   \n",
       "\n",
       "Gene                  MYO1F  BRWD1-AS2  RPS19BP1  AUNIP  TNK2  SUDS3  \n",
       "AAAAACACGATC_Hypoxia      0          0         0      0     0      1  \n",
       "AAAAATGGGGGA_Hypoxia      0          0         0      0     0      0  \n",
       "AAAACATCTTGC_Hypoxia      0          0         1      0     0      0  \n",
       "AAAACCAGCCCA_Hypoxia      0          0         0      0     0      0  \n",
       "AAAACCTTCAAG_Hypoxia      0          0         0      0     0      0  \n",
       "\n",
       "[5 rows x 3000 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab52079",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8cd4e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed0d598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "pca = PCA().fit(X_scaled)\n",
    "\n",
    "cumvar = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.plot(np.arange(1, len(cumvar)+1), cumvar, marker='o')\n",
    "plt.axhline(0.90, color='gray', linestyle='--', label='90% variance')\n",
    "plt.xlabel(\"Number of PCs\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"Elbow Plot: Choosing Number of PCs\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839f5787",
   "metadata": {},
   "source": [
    "Our Elbow Plot shows the cumulative explained variance as a function of the number of principal components used in PCA. The curve helps to decide how many principal components to keep while retaining most of the data’s variability. In this case, we don't see a clear “elbow,” so the threshold of 90% variance (dashed line) is used to select the number of principal components. This ensures that the reduced dataset captures 80% of the total variance, balancing dimensionality reduction with information retention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "374573f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2126\n",
      "(9431, 2126)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca90 = PCA(n_components = 0.90) \n",
    "X_pca90 = pca90.fit_transform(X_scaled)\n",
    "print(pca90.n_components_)\n",
    "print(X_pca90.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a491576",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca90.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4134494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00985089 0.00241797 0.00165    ... 0.00017405 0.00017402 0.00017395]\n"
     ]
    }
   ],
   "source": [
    "print(pca90.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a4b98f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0999938261503368\n"
     ]
    }
   ],
   "source": [
    "print(1 - pca90.explained_variance_ratio_.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcffdbe",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9e70532e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  2 → silhouette = 0.064\n",
      "k =  3 → silhouette = 0.044\n",
      "k =  4 → silhouette = 0.044\n",
      "k =  5 → silhouette = 0.044\n",
      "k =  6 → silhouette = 0.044\n",
      "k =  7 → silhouette = 0.044\n",
      "k =  8 → silhouette = 0.044\n",
      "k =  9 → silhouette = 0.044\n",
      "k = 10 → silhouette = 0.044\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "X_pca = X_pca90  \n",
    "\n",
    "ks = np.arange(2, 11)           \n",
    "sil_scores = []                \n",
    "\n",
    "for k in ks:\n",
    "    km = KMeans(n_clusters=k, random_state=42).fit(X_pca)\n",
    "    labels = km.labels_\n",
    "    sil = silhouette_score(X_pca, labels)\n",
    "    sil_scores.append(sil)\n",
    "    print(f\"k = {k:2d} → silhouette = {sil:.3f}\")\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(ks, sil_scores, marker='o')\n",
    "plt.xticks(ks)\n",
    "plt.xlabel(\"Number of clusters (k)\")\n",
    "plt.ylabel(\"Silhouette score\")\n",
    "plt.title(\"Silhouette analysis for K-Means\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c9ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_clusters = 2\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "cluster_labels = kmeans.fit_predict(X_pca90[:, :70])\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "scatter = plt.scatter(\n",
    "    X_pca90[:,0], X_pca90[:,1],\n",
    "    c=cluster_labels, cmap='tab10', s=10, alpha=0.8\n",
    ")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(f\"KMeans (k={n_clusters}) on PCA space\")\n",
    "plt.legend(*scatter.legend_elements(), title=\"Cluster\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065e7dd5",
   "metadata": {},
   "source": [
    "We have two clusters, namely Hypoxia and Normoxia, so we have k=2. Each point on our graph represents a cell, colored by its assigned cluster (cluster 0 or cluster 1). The plot shows how the cells are distributed in reduced 2D space, making it easier to visualize potential structure. While the clusters overlap somewhat, there is a visible separation along PC1, confirming that the algorithm found two distinct groups in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140a7465",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "76be2a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9431, 3000)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df.T \n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc06f8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    4768\n",
      "0    4663\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample_names_train = X_train.index\n",
    "\n",
    "y_train = np.array([1 if \"Hypoxia\" in name else 0 for name in sample_names_train])\n",
    "\n",
    "print(pd.Series(y_train, index=sample_names_train).value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9ef63f",
   "metadata": {},
   "source": [
    "## Finding the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bb6784",
   "metadata": {},
   "source": [
    "We now prepare a set of classification models to compare. We import six different models: Logistic Regression, Random Forest, SVM, Naive Bayes, K-Nearest Neighbors, and Decision Tree. We will evaluate their performance on our data based on cross validation accuracy and accuracy on training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "49603e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, solver='liblinear'),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"SVM\": SVC(kernel='linear'),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1252ce8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: CV accuracy = 0.9114\n",
      "Logistic Regression: Training accuracy = 0.9064\n",
      "Random Forest: CV accuracy = 0.9039\n",
      "Random Forest: Training accuracy = 0.9858\n",
      "SVM: CV accuracy = 0.9104\n",
      "SVM: Training accuracy = 0.9062\n",
      "Naive Bayes: CV accuracy = 0.8811\n",
      "Naive Bayes: Training accuracy = 0.8792\n",
      "KNN: CV accuracy = 0.8925\n",
      "KNN: Training accuracy = 0.9023\n",
      "Decision Tree: CV accuracy = 0.8678\n",
      "Decision Tree: Training accuracy = 0.9858\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline([\n",
    "        (\"scale\", StandardScaler()),\n",
    "        (\"var_thresh\", VarianceThreshold(threshold=0.0)),\n",
    "        (\"select\", SelectKBest(score_func=f_classif)), \n",
    "        (\"pca\", PCA(random_state=42)), \n",
    "        (\"clf\", model)\n",
    "    ])\n",
    "    scores = cross_val_score(pipe, X_train, y_train, cv=5)\n",
    "    results[name] = scores.mean()\n",
    "    print(f\"{name}: CV accuracy = {scores.mean():.4f}\")\n",
    "    print(f\"{name}: Training accuracy = {pipe.fit(X_train, y_train).score(X_train, y_train):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a1bf888c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression   CV Accuracy: 0.9114\n",
      "SVM                   CV Accuracy: 0.9104\n",
      "Random Forest         CV Accuracy: 0.9039\n",
      "KNN                   CV Accuracy: 0.8925\n",
      "Naive Bayes           CV Accuracy: 0.8811\n",
      "Decision Tree         CV Accuracy: 0.8678\n"
     ]
    }
   ],
   "source": [
    "sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "for name, score in sorted_results:\n",
    "    print(f\"{name:<20}  CV Accuracy: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de13d417",
   "metadata": {},
   "source": [
    "SVM and Logistic Regression models give better accuracy scores than others. Now we will perform randomized search to tune best-performing models in order get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "41ece182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Best CV accuracy: 0.9869579382215604\n",
      "Training accuracy: 0.9928957692715513\n",
      "Best parameters: {'clf__C': 0.01768682900898522, 'pca__n_components': 200, 'select__k': 600}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import loguniform\n",
    "import numpy as np\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"var_thresh\", VarianceThreshold(threshold=0.0)),\n",
    "    (\"select\", SelectKBest(score_func=f_classif)), \n",
    "    (\"pca\", PCA(random_state=42)),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, solver='liblinear', random_state=42))\n",
    "])\n",
    "\n",
    "param_distributions = {\n",
    "    \"select__k\": np.arange(100, 1001, 100),\n",
    "    \"pca__n_components\": np.arange(50, 201, 50),\n",
    "    \"clf__C\": loguniform(1e-3, 1e3),\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "search_lr = RandomizedSearchCV(\n",
    "    pipe,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=30,\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "search_lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best CV accuracy:\", search_lr.best_score_)\n",
    "print (\"Training accuracy:\", search_lr.score(X_train, y_train))\n",
    "print(\"Best parameters:\", search_lr.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dab173",
   "metadata": {},
   "source": [
    "Tuning improved our model: the training and CV accuracies are close, and give excellent scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d0d41f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best CV accuracy: 0.9866397034000189\n",
      "Training accuracy: 0.9907751033824621\n",
      "Best parameters: {'clf__C': 0.030771802712506867, 'pca__n_components': 50, 'select__k': 600}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import loguniform\n",
    "import numpy as np\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"var_thresh\", VarianceThreshold(threshold=0.0)),\n",
    "    (\"select\", SelectKBest(score_func=f_classif)), \n",
    "    (\"pca\", PCA(random_state=42)),\n",
    "    (\"clf\", SVC(kernel='linear', probability=True, random_state=42))  \n",
    "])\n",
    "\n",
    "param_distributions = {\n",
    "    \"select__k\": np.arange(200, 1001, 200),\n",
    "    \"pca__n_components\": np.arange(50, 201, 50),\n",
    "    \"clf__C\": loguniform(1e-2, 1e2),           \n",
    "}\n",
    "\n",
    "search_svm = RandomizedSearchCV(\n",
    "    pipe,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best CV accuracy:\", search_svm.best_score_)\n",
    "print(\"Training accuracy:\", search_svm.score(X_train, y_train))\n",
    "print(\"Best parameters:\", search_svm.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abd24fa",
   "metadata": {},
   "source": [
    "The tuned SVM model achieved excellent CV accuracy. Both Logistic Regression and SVM now perform very well on our classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1646ab9",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e65ab5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:9: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/var/folders/2w/l87wj0c90l94mncxh8y9wwth0000gn/T/ipykernel_19692/2968296409.py:9: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  sep='\\s+',\n"
     ]
    }
   ],
   "source": [
    "file_path = '/Users/dogao/Desktop/OneDrive_1_4-3-2025/MCF7_Filtered_Normalised_3000_Data_test_anonim.txt'\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    header = f.readline().replace('\"', '').strip().split()\n",
    "\n",
    "header = ['Gene'] + header\n",
    "\n",
    "df_test = pd.read_csv(file_path,\n",
    "                 sep='\\s+',        \n",
    "                 quotechar='\"',   \n",
    "                 skiprows=1,       \n",
    "                 header=None)     \n",
    "\n",
    "df_test.columns = header\n",
    "df_test.set_index('Gene', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e14b0544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 5406)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3c689a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e519469d",
   "metadata": {},
   "source": [
    "### Loading our Best models for both classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64360dfe",
   "metadata": {},
   "source": [
    "Our two best models are Logistic Regression and SVM. We will use them on the test set to make predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f2233e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('var_thresh', VarianceThreshold()),\n",
      "                ('select', SelectKBest(k=600)),\n",
      "                ('pca', PCA(n_components=200, random_state=42)),\n",
      "                ('clf',\n",
      "                 LogisticRegression(C=0.01768682900898522, max_iter=1000,\n",
      "                                    random_state=42, solver='liblinear'))])\n"
     ]
    }
   ],
   "source": [
    "model_lr = search_lr.best_estimator_\n",
    "print(\"Best model:\", model_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1fa5bee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('var_thresh', VarianceThreshold()),\n",
      "                ('select', SelectKBest(k=600)),\n",
      "                ('pca', PCA(n_components=50, random_state=42)),\n",
      "                ('clf',\n",
      "                 SVC(C=0.030771802712506867, kernel='linear', probability=True,\n",
      "                     random_state=42))])\n"
     ]
    }
   ],
   "source": [
    "model_svm = search_svm.best_estimator_\n",
    "print(\"Best model:\", model_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "52d27e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [1 0 0 1 1 1 0 1 1 0]\n",
      "Predicted labels shape: (5406,)\n"
     ]
    }
   ],
   "source": [
    "label_predict_lr = model_lr.predict(X_test)\n",
    "print(\"Predicted labels:\", label_predict_lr[:10])\n",
    "print(\"Predicted labels shape:\", label_predict_lr.shape)\n",
    "\n",
    "with open(\"predictions_MCF7_DropSeq.txt\", \"w\") as f:\n",
    "    for label in label_predict_lr:\n",
    "        f.write(f\"{label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1dc5829a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [1 0 0 1 1 1 0 1 1 0]\n",
      "Predicted labels shape: (5406,)\n"
     ]
    }
   ],
   "source": [
    "label_predict_svm= model_svm.predict(X_test)\n",
    "print(\"Predicted labels:\", label_predict_svm[:10])\n",
    "print(\"Predicted labels shape:\", label_predict_svm.shape)\n",
    "\n",
    "with open(\"predictions_rf.txt\", \"w\") as f:\n",
    "    for label in label_predict_svm:\n",
    "        f.write(f\"{label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "858cbae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mismatches: 132\n"
     ]
    }
   ],
   "source": [
    "mask = label_predict_svm != label_predict_lr\n",
    "print(\"Number of mismatches:\", mask.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c53450",
   "metadata": {},
   "source": [
    "Since there are very few mismatches between the predictions of our two models, both can be used to make predictions on the test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
